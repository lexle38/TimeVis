"""
TimeVis é¡¹ç›®çŠ¶æ€æ£€æŸ¥å·¥å…·
æ£€æŸ¥é¡¹ç›®å®Œæ•´æ€§ã€æ•°æ®çŠ¶æ€ã€æ¨¡å‹çŠ¶æ€å’Œè¿è¡Œç¯å¢ƒ
"""

import os
import json
import sys
from pathlib import Path
from datetime import datetime
import pandas as pd

def print_banner():
    """æ‰“å°æ¨ªå¹…"""
    print("=" * 80)
    print("TimeVis é¡¹ç›®çŠ¶æ€æ£€æŸ¥")
    print(f"æ£€æŸ¥æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)

def check_project_structure():
    """æ£€æŸ¥é¡¹ç›®ç»“æ„"""
    print("\nğŸ“ é¡¹ç›®ç»“æ„æ£€æŸ¥")
    print("-" * 40)
    
    required_files = [
        "data_processing.py",
        "model_training.py", 
        "quick_start.py",
        "setup_environment.py",
        "requirements.txt",
        "QUICK_START.md",
        "DATA_PROCESSING_GUIDE.md"
    ]
    
    required_dirs = [
        "data",
        "backend", 
        "frontend",
        "models",
        "results"
    ]
    
    # æ£€æŸ¥æ–‡ä»¶
    missing_files = []
    for file_name in required_files:
        if Path(file_name).exists():
            print(f"  âœ… {file_name}")
        else:
            print(f"  âŒ {file_name}")
            missing_files.append(file_name)
    
    # æ£€æŸ¥ç›®å½•
    missing_dirs = []
    for dir_name in required_dirs:
        if Path(dir_name).exists():
            print(f"  âœ… {dir_name}/")
        else:
            print(f"  âŒ {dir_name}/")
            missing_dirs.append(dir_name)
    
    return len(missing_files) == 0 and len(missing_dirs) == 0

def check_data_status():
    """æ£€æŸ¥æ•°æ®çŠ¶æ€"""
    print("\nğŸ“Š æ•°æ®çŠ¶æ€æ£€æŸ¥")
    print("-" * 40)
    
    data_dir = Path("data")
    processed_dir = data_dir / "processed"
    
    # æ£€æŸ¥åŸå§‹æ•°æ®
    print("åŸå§‹æ•°æ®:")
    raw_files = ["weather.csv", "electricity.csv"]
    raw_data_ok = True
    
    for file_name in raw_files:
        file_path = data_dir / file_name
        if file_path.exists():
            size_mb = file_path.stat().st_size / (1024 * 1024)
            print(f"  âœ… {file_name} ({size_mb:.1f}MB)")
        else:
            print(f"  âŒ {file_name} (ç¼ºå¤±)")
            raw_data_ok = False
    
    # æ£€æŸ¥å¤„ç†åæ•°æ®
    print("\nå¤„ç†åæ•°æ®:")
    if processed_dir.exists():
        processed_files = list(processed_dir.glob("*.csv"))
        if processed_files:
            for file_path in processed_files:
                size_mb = file_path.stat().st_size / (1024 * 1024)
                print(f"  âœ… {file_path.name} ({size_mb:.1f}MB)")
        else:
            print("  âš ï¸  æš‚æ— å¤„ç†åæ•°æ®")
        
        # æ£€æŸ¥æ•°æ®é›†ä¿¡æ¯
        info_file = processed_dir / "datasets_info.json"
        if info_file.exists():
            try:
                with open(info_file, 'r', encoding='utf-8') as f:
                    info = json.load(f)
                print(f"  âœ… datasets_info.json ({len(info)}ä¸ªæ•°æ®é›†)")
            except:
                print("  âŒ datasets_info.json (æ ¼å¼é”™è¯¯)")
        else:
            print("  âš ï¸  datasets_info.json (æœªç”Ÿæˆ)")
    else:
        print("  âš ï¸  processedç›®å½•ä¸å­˜åœ¨")
    
    return raw_data_ok

def check_model_status():
    """æ£€æŸ¥æ¨¡å‹çŠ¶æ€"""
    print("\nğŸ¤– æ¨¡å‹çŠ¶æ€æ£€æŸ¥")
    print("-" * 40)
    
    models_dir = Path("models")
    
    if not models_dir.exists():
        print("  âš ï¸  modelsç›®å½•ä¸å­˜åœ¨")
        return False
    
    model_files = list(models_dir.glob("*.pth"))
    
    if not model_files:
        print("  âš ï¸  æš‚æ— è®­ç»ƒå¥½çš„æ¨¡å‹")
        return False
    
    print("å·²è®­ç»ƒæ¨¡å‹:")
    for model_path in model_files:
        size_mb = model_path.stat().st_size / (1024 * 1024)
        mod_time = datetime.fromtimestamp(model_path.stat().st_mtime)
        print(f"  âœ… {model_path.name} ({size_mb:.1f}MB, {mod_time.strftime('%Y-%m-%d %H:%M')})")
    
    return True

def check_results_status():
    """æ£€æŸ¥ç»“æœçŠ¶æ€"""
    print("\nğŸ“ˆ ç»“æœçŠ¶æ€æ£€æŸ¥")
    print("-" * 40)
    
    results_dir = Path("results")
    
    if not results_dir.exists():
        print("  âš ï¸  resultsç›®å½•ä¸å­˜åœ¨")
        return False
    
    # æ£€æŸ¥ç»“æœæ–‡ä»¶
    result_files = {
        "*.json": "è®­ç»ƒç»“æœ",
        "*.csv": "æ•°æ®æŠ¥å‘Š", 
        "*.html": "å¯è§†åŒ–æŠ¥å‘Š",
        "*.png": "å›¾è¡¨æ–‡ä»¶"
    }
    
    has_results = False
    for pattern, desc in result_files.items():
        files = list(results_dir.glob(pattern))
        if files:
            print(f"\n{desc}:")
            for file_path in files:
                size_kb = file_path.stat().st_size / 1024
                mod_time = datetime.fromtimestamp(file_path.stat().st_mtime)
                print(f"  âœ… {file_path.name} ({size_kb:.1f}KB, {mod_time.strftime('%Y-%m-%d %H:%M')})")
            has_results = True
    
    if not has_results:
        print("  âš ï¸  æš‚æ— ç»“æœæ–‡ä»¶")
    
    return has_results

def check_environment():
    """æ£€æŸ¥è¿è¡Œç¯å¢ƒ"""
    print("\nğŸ”§ ç¯å¢ƒçŠ¶æ€æ£€æŸ¥")
    print("-" * 40)
    
    # Pythonç‰ˆæœ¬
    python_version = f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}"
    print(f"Pythonç‰ˆæœ¬: {python_version}")
    
    # å…³é”®åŒ…æ£€æŸ¥
    packages = {
        'torch': 'PyTorch',
        'pandas': 'Pandas', 
        'numpy': 'NumPy',
        'sklearn': 'Scikit-learn',
        'matplotlib': 'Matplotlib',
        'flask': 'Flask'
    }
    
    env_ok = True
    print("\næ ¸å¿ƒä¾èµ–:")
    for package, name in packages.items():
        try:
            if package == 'sklearn':
                import sklearn
                version = sklearn.__version__
            else:
                module = __import__(package)
                version = getattr(module, '__version__', 'unknown')
            print(f"  âœ… {name} ({version})")
        except ImportError:
            print(f"  âŒ {name} (æœªå®‰è£…)")
            env_ok = False
    
    # GPUæ£€æŸ¥
    try:
        import torch
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            print(f"\nGPU: âœ… {gpu_name}")
        else:
            print(f"\nGPU: âš ï¸  CUDAä¸å¯ç”¨")
    except:
        print(f"\nGPU: âŒ æ— æ³•æ£€æŸ¥")
    
    return env_ok

def check_web_components():
    """æ£€æŸ¥Webç»„ä»¶çŠ¶æ€"""
    print("\nğŸŒ Webç»„ä»¶æ£€æŸ¥")
    print("-" * 40)
    
    # åç«¯æ£€æŸ¥
    backend_dir = Path("backend")
    if backend_dir.exists():
        backend_files = ["app.py", "models.py", "api.py"]
        print("åç«¯ç»„ä»¶:")
        for file_name in backend_files:
            file_path = backend_dir / file_name
            if file_path.exists():
                print(f"  âœ… {file_name}")
            else:
                print(f"  âš ï¸  {file_name} (ç¼ºå¤±)")
    else:
        print("âŒ backendç›®å½•ä¸å­˜åœ¨")
    
    # å‰ç«¯æ£€æŸ¥
    frontend_dir = Path("frontend")
    if frontend_dir.exists():
        package_json = frontend_dir / "package.json"
        if package_json.exists():
            print("å‰ç«¯ç»„ä»¶:")
            print("  âœ… package.json")
            
            node_modules = frontend_dir / "node_modules"
            if node_modules.exists():
                print("  âœ… node_modules (å·²å®‰è£…ä¾èµ–)")
            else:
                print("  âš ï¸  node_modules (éœ€è¦è¿è¡Œ npm install)")
        else:
            print("âŒ å‰ç«¯package.jsonä¸å­˜åœ¨")
    else:
        print("âŒ frontendç›®å½•ä¸å­˜åœ¨")

def generate_status_report():
    """ç”ŸæˆçŠ¶æ€æŠ¥å‘Š"""
    print("\nğŸ“‹ ç”ŸæˆçŠ¶æ€æŠ¥å‘Š")
    print("-" * 40)
    
    report = {
        "æ£€æŸ¥æ—¶é—´": datetime.now().isoformat(),
        "é¡¹ç›®çŠ¶æ€": "å®Œæ•´" if check_project_structure() else "ä¸å®Œæ•´",
        "æ•°æ®çŠ¶æ€": "å¯ç”¨" if check_data_status() else "ç¼ºå¤±",
        "æ¨¡å‹çŠ¶æ€": "å·²è®­ç»ƒ" if check_model_status() else "æœªè®­ç»ƒ", 
        "ç¯å¢ƒçŠ¶æ€": "æ­£å¸¸" if check_environment() else "å¼‚å¸¸"
    }
    
    # ä¿å­˜æŠ¥å‘Š
    with open("PROJECT_STATUS.json", "w", encoding="utf-8") as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print("âœ… çŠ¶æ€æŠ¥å‘Šå·²ä¿å­˜: PROJECT_STATUS.json")

def provide_recommendations():
    """æä¾›å»ºè®®"""
    print("\nğŸ’¡ æ“ä½œå»ºè®®")
    print("-" * 40)
    
    # æ£€æŸ¥å„ä¸ªçŠ¶æ€å¹¶ç»™å‡ºå»ºè®®
    if not Path("data/weather.csv").exists() or not Path("data/electricity.csv").exists():
        print("â— æ•°æ®æ–‡ä»¶ç¼ºå¤±:")
        print("   è¯·ç¡®ä¿ weather.csv å’Œ electricity.csv åœ¨ data/ ç›®å½•ä¸‹")
    
    if not Path("data/processed").exists() or not list(Path("data/processed").glob("*.csv")):
        print("â— éœ€è¦æ•°æ®å¤„ç†:")
        print("   è¿è¡Œ: python data_processing.py")
        print("   æˆ–: python quick_start.py --data-only")
    
    if not Path("models").exists() or not list(Path("models").glob("*.pth")):
        print("â— éœ€è¦æ¨¡å‹è®­ç»ƒ:")
        print("   è¿è¡Œ: python model_training.py") 
        print("   æˆ–: python quick_start.py --model-only")
    
    if not Path("results").exists() or not list(Path("results").glob("*")):
        print("â— éœ€è¦ç”Ÿæˆç»“æœ:")
        print("   è¿è¡Œå®Œæ•´æµç¨‹: python quick_start.py")
    
    print("\nğŸš€ å¿«é€Ÿå¯åŠ¨:")
    print("   ä¸€é”®è¿è¡Œ: start_timevis.bat")
    print("   æˆ–: python quick_start.py")

def main():
    """ä¸»å‡½æ•°"""
    print_banner()
    
    # æ‰§è¡Œå„é¡¹æ£€æŸ¥
    check_project_structure()
    check_data_status()
    check_model_status()
    check_results_status()
    check_environment()
    check_web_components()
    
    # ç”ŸæˆæŠ¥å‘Šå’Œå»ºè®®
    generate_status_report()
    provide_recommendations()
    
    print("\n" + "=" * 80)
    print("çŠ¶æ€æ£€æŸ¥å®Œæˆï¼")
    print("=" * 80)

if __name__ == "__main__":
    main()
